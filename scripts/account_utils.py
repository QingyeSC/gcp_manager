#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
GCPè´¦å·ç®¡ç†è¾…åŠ©å·¥å…·
æä¾›æ‰¹é‡å¯¼å…¥ã€éªŒè¯ã€ç»Ÿè®¡ç­‰åŠŸèƒ½
"""

import os
import json
import shutil
import argparse
from pathlib import Path
from datetime import datetime
import re

class AccountUtils:
    def __init__(self):
        self.base_dir = Path(__file__).parent.parent
        self.accounts_dir = self.base_dir / "accounts"
        
        # ç¡®ä¿ç›®å½•å­˜åœ¨
        for subdir in ["fresh", "uploaded", "exhausted_300", "activated", "exhausted_100", "archive"]:
            (self.accounts_dir / subdir).mkdir(parents=True, exist_ok=True)
    
    def validate_json_file(self, file_path):
        """éªŒè¯JSONæ–‡ä»¶æ˜¯å¦ä¸ºæœ‰æ•ˆçš„GCPæœåŠ¡è´¦å·å¯†é’¥"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            # æ£€æŸ¥å¿…è¦å­—æ®µ
            required_fields = [
                'type', 'project_id', 'private_key_id', 'private_key', 
                'client_email', 'client_id', 'auth_uri', 'token_uri'
            ]
            
            for field in required_fields:
                if field not in data:
                    return False, f"ç¼ºå°‘å¿…è¦å­—æ®µ: {field}"
            
            # æ£€æŸ¥ç±»å‹æ˜¯å¦ä¸ºservice_account
            if data.get('type') != 'service_account':
                return False, f"ç±»å‹ä¸æ­£ç¡®: {data.get('type')}, åº”ä¸º service_account"
            
            # æ£€æŸ¥ç§é’¥æ ¼å¼
            private_key = data.get('private_key', '')
            if not private_key.startswith('-----BEGIN PRIVATE KEY-----'):
                return False, "ç§é’¥æ ¼å¼ä¸æ­£ç¡®"
            
            return True, "éªŒè¯é€šè¿‡"
            
        except json.JSONDecodeError as e:
            return False, f"JSONæ ¼å¼é”™è¯¯: {e}"
        except Exception as e:
            return False, f"éªŒè¯å¤±è´¥: {e}"
    
    def validate_account_group(self, group_prefix, directory):
        """éªŒè¯è´¦å·ç»„çš„å®Œæ•´æ€§"""
        dir_path = self.accounts_dir / directory
        
        missing_files = []
        invalid_files = []
        
        for suffix in ['01', '02', '03']:
            filename = f"{group_prefix}-{suffix}.json"
            file_path = dir_path / filename
            
            if not file_path.exists():
                missing_files.append(filename)
                continue
            
            is_valid, message = self.validate_json_file(file_path)
            if not is_valid:
                invalid_files.append(f"{filename}: {message}")
        
        is_complete = len(missing_files) == 0 and len(invalid_files) == 0
        
        return {
            'complete': is_complete,
            'missing_files': missing_files,
            'invalid_files': invalid_files
        }
    
    def import_account_files(self, source_directory, target_directory="fresh", 
                           validate=True, rename_pattern=None):
        """æ‰¹é‡å¯¼å…¥è´¦å·æ–‡ä»¶"""
        source_path = Path(source_directory)
        target_path = self.accounts_dir / target_directory
        
        if not source_path.exists():
            print(f"âŒ æºç›®å½•ä¸å­˜åœ¨: {source_path}")
            return
        
        json_files = list(source_path.glob("*.json"))
        if not json_files:
            print(f"âŒ æºç›®å½•ä¸­æ²¡æœ‰JSONæ–‡ä»¶: {source_path}")
            return
        
        print(f"ğŸ“ å‘ç° {len(json_files)} ä¸ªJSONæ–‡ä»¶")
        
        imported_count = 0
        failed_count = 0
        
        for file_path in json_files:
            try:
                # éªŒè¯æ–‡ä»¶
                if validate:
                    is_valid, message = self.validate_json_file(file_path)
                    if not is_valid:
                        print(f"âŒ {file_path.name}: {message}")
                        failed_count += 1
                        continue
                
                # ç¡®å®šç›®æ ‡æ–‡ä»¶å
                if rename_pattern:
                    # ä½¿ç”¨é‡å‘½åæ¨¡å¼
                    target_filename = rename_pattern.format(
                        original_name=file_path.stem,
                        timestamp=datetime.now().strftime("%Y%m%d%H%M%S")
                    ) + ".json"
                else:
                    target_filename = file_path.name
                
                target_file_path = target_path / target_filename
                
                # æ£€æŸ¥ç›®æ ‡æ–‡ä»¶æ˜¯å¦å·²å­˜åœ¨
                if target_file_path.exists():
                    print(f"âš ï¸ æ–‡ä»¶å·²å­˜åœ¨ï¼Œè·³è¿‡: {target_filename}")
                    continue
                
                # å¤åˆ¶æ–‡ä»¶
                shutil.copy2(file_path, target_file_path)
                print(f"âœ“ å¯¼å…¥æˆåŠŸ: {file_path.name} -> {target_filename}")
                imported_count += 1
                
            except Exception as e:
                print(f"âŒ å¯¼å…¥å¤±è´¥ {file_path.name}: {e}")
                failed_count += 1
        
        print(f"\nğŸ“Š å¯¼å…¥å®Œæˆ:")
        print(f"  æˆåŠŸ: {imported_count} ä¸ª")
        print(f"  å¤±è´¥: {failed_count} ä¸ª")
    
    def check_account_groups(self, directory="fresh"):
        """æ£€æŸ¥è´¦å·ç»„çš„å®Œæ•´æ€§"""
        dir_path = self.accounts_dir / directory
        
        if not dir_path.exists():
            print(f"âŒ ç›®å½•ä¸å­˜åœ¨: {dir_path}")
            return
        
        # è·å–æ‰€æœ‰JSONæ–‡ä»¶
        json_files = list(dir_path.glob("*.json"))
        
        if not json_files:
            print(f"ğŸ“ ç›®å½•ä¸­æ²¡æœ‰JSONæ–‡ä»¶: {dir_path}")
            return
        
        # æŒ‰å‰ç¼€åˆ†ç»„
        groups = {}
        for file_path in json_files:
            # æå–å‰ç¼€ (å»æ‰-01/-02/-03å’Œ-activedåç¼€)
            name = file_path.stem
            if name.endswith('-actived'):
                name = name[:-8]  # å»æ‰-actived
            
            parts = name.split('-')
            if len(parts) >= 4:
                prefix = '-'.join(parts[:-1])
                if prefix not in groups:
                    groups[prefix] = []
                groups[prefix].append(file_path)
        
        print(f"ğŸ“Š {directory} ç›®å½•ä¸­çš„è´¦å·ç»„:")
        print("=" * 60)
        
        complete_groups = 0
        incomplete_groups = 0
        
        for prefix, files in groups.items():
            file_count = len(files)
            status = "âœ“ å®Œæ•´" if file_count == 3 else f"âŒ ä¸å®Œæ•´ ({file_count}/3)"
            
            if file_count == 3:
                complete_groups += 1
            else:
                incomplete_groups += 1
            
            print(f"{prefix:<30} {status}")
            
            # æ˜¾ç¤ºæ–‡ä»¶è¯¦æƒ…
            for file_path in sorted(files):
                size_kb = file_path.stat().st_size / 1024
                modified = datetime.fromtimestamp(file_path.stat().st_mtime).strftime('%Y-%m-%d %H:%M')
                print(f"  â””â”€ {file_path.name:<25} ({size_kb:.1f}KB, {modified})")
        
        print("=" * 60)
        print(f"æ€»è®¡: {complete_groups} ä¸ªå®Œæ•´ç»„, {incomplete_groups} ä¸ªä¸å®Œæ•´ç»„")
    
    def cleanup_incomplete_groups(self, directory="fresh", action="move"):
        """æ¸…ç†ä¸å®Œæ•´çš„è´¦å·ç»„"""
        dir_path = self.accounts_dir / directory
        
        if not dir_path.exists():
            print(f"âŒ ç›®å½•ä¸å­˜åœ¨: {dir_path}")
            return
        
        # è·å–æ‰€æœ‰JSONæ–‡ä»¶å¹¶åˆ†ç»„
        json_files = list(dir_path.glob("*.json"))
        groups = {}
        
        for file_path in json_files:
            name = file_path.stem
            if name.endswith('-actived'):
                name = name[:-8]
            
            parts = name.split('-')
            if len(parts) >= 4:
                prefix = '-'.join(parts[:-1])
                if prefix not in groups:
                    groups[prefix] = []
                groups[prefix].append(file_path)
        
        # æ‰¾å‡ºä¸å®Œæ•´çš„ç»„
        incomplete_groups = {prefix: files for prefix, files in groups.items() if len(files) != 3}
        
        if not incomplete_groups:
            print("âœ“ æ‰€æœ‰è´¦å·ç»„éƒ½æ˜¯å®Œæ•´çš„")
            return
        
        print(f"å‘ç° {len(incomplete_groups)} ä¸ªä¸å®Œæ•´çš„è´¦å·ç»„:")
        
        # åˆ›å»ºæ¸…ç†ç›®å½•
        if action == "move":
            cleanup_dir = self.accounts_dir / "cleanup" / datetime.now().strftime("%Y%m%d_%H%M%S")
            cleanup_dir.mkdir(parents=True, exist_ok=True)
        
        cleaned_count = 0
        for prefix, files in incomplete_groups.items():
            print(f"  {prefix} ({len(files)}/3 ä¸ªæ–‡ä»¶)")
            
            for file_path in files:
                if action == "move":
                    target_path = cleanup_dir / file_path.name
                    shutil.move(str(file_path), str(target_path))
                    print(f"    ç§»åŠ¨: {file_path.name} -> {target_path}")
                elif action == "delete":
                    file_path.unlink()
                    print(f"    åˆ é™¤: {file_path.name}")
                
                cleaned_count += 1
        
        if action == "move":
            print(f"\nâœ“ å·²å°† {cleaned_count} ä¸ªä¸å®Œæ•´æ–‡ä»¶ç§»åŠ¨åˆ°: {cleanup_dir}")
        else:
            print(f"\nâœ“ å·²åˆ é™¤ {cleaned_count} ä¸ªä¸å®Œæ•´æ–‡ä»¶")
    
    def generate_statistics(self):
        """ç”Ÿæˆè´¦å·ç»Ÿè®¡æŠ¥å‘Š"""
        print("ğŸ“Š GCPè´¦å·ç®¡ç†ç»Ÿè®¡æŠ¥å‘Š")
        print("=" * 60)
        print(f"ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        print()
        
        directories = ["fresh", "uploaded", "exhausted_300", "activated", "exhausted_100", "archive"]
        total_groups = 0
        total_files = 0
        
        for directory in directories:
            dir_path = self.accounts_dir / directory
            
            if not dir_path.exists():
                continue
            
            json_files = list(dir_path.glob("*.json"))
            file_count = len(json_files)
            
            # ç»Ÿè®¡å®Œæ•´ç»„æ•°
            groups = {}
            for file_path in json_files:
                name = file_path.stem
                if name.endswith('-actived'):
                    name = name[:-8]
                
                parts = name.split('-')
                if len(parts) >= 4:
                    prefix = '-'.join(parts[:-1])
                    if prefix not in groups:
                        groups[prefix] = []
                    groups[prefix].append(file_path)
            
            complete_groups = len([g for g in groups.values() if len(g) == 3])
            incomplete_groups = len(groups) - complete_groups
            
            # è®¡ç®—æ€»å¤§å°
            total_size = sum(f.stat().st_size for f in json_files)
            total_size_mb = total_size / (1024 * 1024)
            
            # å¦‚æœæœ‰æ•°æ®åº“è®°å½•ï¼Œä¹Ÿæ˜¾ç¤ºä½¿ç”¨é¢åº¦ä¿¡æ¯
            conn = self.get_db_connection() if hasattr(self, 'get_db_connection') else None
            total_quota_dollars = 0
            if conn:
                try:
                    cursor = conn.cursor()
                    file_names = [f.stem for f in json_files]
                    if file_names:
                        placeholders = ','.join(['?' for _ in file_names])
                        cursor.execute(f'''
                            SELECT SUM(used_quota) as total_quota 
                            FROM account_status 
                            WHERE account_name IN ({placeholders})
                        ''', file_names)
                        result = cursor.fetchone()
                        if result and result[0]:
                            total_quota_dollars = result[0] / 500000
                    cursor.close()
                    conn.close()
                except:
                    pass
            
            quota_str = f"  ${total_quota_dollars:.2f}" if total_quota_dollars > 0 else ""
            print(f"{directory:<15} {complete_groups:>3} å®Œæ•´ç»„  {incomplete_groups:>3} ä¸å®Œæ•´ç»„  {file_count:>3} æ–‡ä»¶  {total_size_mb:>6.1f}MB{quota_str}")
            
            total_groups += complete_groups
            total_files += file_count
        
        print("-" * 60)
        print(f"{'æ€»è®¡':<15} {total_groups:>3} å®Œæ•´ç»„  {total_files:>18} æ–‡ä»¶")
        print()
        
        # ç³»ç»Ÿå»ºè®®
        fresh_groups = len([g for g in self.get_groups("fresh") if len(g) == 3])
        activated_groups = len([g for g in self.get_groups("activated") if len(g) == 3])
        pending_groups = len([g for g in self.get_groups("exhausted_300") if len(g) == 3])
        
        print("ğŸ’¡ ç³»ç»Ÿå»ºè®®:")
        if fresh_groups < 5:
            print("  âš ï¸ æ–°è´¦å·æ± ä¸è¶³ï¼Œå»ºè®®è¡¥å……æ–°è´¦å·")
        if pending_groups > 0:
            print(f"  âš ï¸ æœ‰ {pending_groups} ä¸ªè´¦å·ç»„å¾…æ¿€æ´»")
        if activated_groups > 0:
            print(f"  âœ“ æœ‰ {activated_groups} ä¸ªå·²æ¿€æ´»è´¦å·å¯ç”¨")
    
    def get_groups(self, directory):
        """è·å–ç›®å½•ä¸­çš„è´¦å·ç»„"""
        dir_path = self.accounts_dir / directory
        
        if not dir_path.exists():
            return {}
        
        json_files = list(dir_path.glob("*.json"))
        groups = {}
        
        for file_path in json_files:
            name = file_path.stem
            if name.endswith('-actived'):
                name = name[:-8]
            
            parts = name.split('-')
            if len(parts) >= 4:
                prefix = '-'.join(parts[:-1])
                if prefix not in groups:
                    groups[prefix] = []
                groups[prefix].append(file_path)
        
        return groups

def main():
    parser = argparse.ArgumentParser(description='GCPè´¦å·ç®¡ç†è¾…åŠ©å·¥å…·')
    subparsers = parser.add_subparsers(dest='command', help='å¯ç”¨å‘½ä»¤')
    
    # å¯¼å…¥å‘½ä»¤
    import_parser = subparsers.add_parser('import', help='æ‰¹é‡å¯¼å…¥è´¦å·æ–‡ä»¶')
    import_parser.add_argument('source', help='æºç›®å½•è·¯å¾„')
    import_parser.add_argument('--target', default='fresh', help='ç›®æ ‡ç›®å½• (é»˜è®¤: fresh)')
    import_parser.add_argument('--no-validate', action='store_true', help='è·³è¿‡æ–‡ä»¶éªŒè¯')
    import_parser.add_argument('--rename', help='é‡å‘½åæ¨¡å¼ (å¦‚: proj-{original_name})')
    
    # æ£€æŸ¥å‘½ä»¤
    check_parser = subparsers.add_parser('check', help='æ£€æŸ¥è´¦å·ç»„å®Œæ•´æ€§')
    check_parser.add_argument('--directory', default='fresh', help='æ£€æŸ¥ç›®å½• (é»˜è®¤: fresh)')
    
    # æ¸…ç†å‘½ä»¤
    cleanup_parser = subparsers.add_parser('cleanup', help='æ¸…ç†ä¸å®Œæ•´çš„è´¦å·ç»„')
    cleanup_parser.add_argument('--directory', default='fresh', help='æ¸…ç†ç›®å½• (é»˜è®¤: fresh)')
    cleanup_parser.add_argument('--action', choices=['move', 'delete'], default='move', 
                               help='æ¸…ç†åŠ¨ä½œ: move(ç§»åŠ¨) æˆ– delete(åˆ é™¤)')
    
    # ç»Ÿè®¡å‘½ä»¤
    subparsers.add_parser('stats', help='ç”Ÿæˆç»Ÿè®¡æŠ¥å‘Š')
    
    args = parser.parse_args()
    
    if not args.command:
        parser.print_help()
        return
    
    utils = AccountUtils()
    
    if args.command == 'import':
        utils.import_account_files(
            args.source, 
            args.target, 
            validate=not args.no_validate,
            rename_pattern=args.rename
        )
    elif args.command == 'check':
        utils.check_account_groups(args.directory)
    elif args.command == 'cleanup':
        utils.cleanup_incomplete_groups(args.directory, args.action)
    elif args.command == 'stats':
        utils.generate_statistics()

if __name__ == "__main__":
    main()