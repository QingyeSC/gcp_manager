#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
é€šé“ç›‘æ§è¿ç»´è„šæœ¬ - åŸºäºç”¨æˆ·åŸå§‹ä»£ç æ”¹è¿›
åŠŸèƒ½ï¼šç›‘æ§APIé€šé“çŠ¶æ€ï¼Œè‡ªåŠ¨è¡¥å……æœ‰æ•ˆé€šé“æ•°é‡
"""

import os
import sys
import json
import logging
import requests
import subprocess
from datetime import datetime
from typing import Dict, Any, Tuple
from pathlib import Path

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('logs/uptime_monitor.log', encoding='utf-8'),
        logging.StreamHandler(sys.stdout)
    ]
)
logger = logging.getLogger(__name__)

class UptimeMonitor:
    """é€šé“ç›‘æ§ç±» - åŸºäºç”¨æˆ·åŸå§‹ç›‘æ§é€»è¾‘"""
    
    def __init__(self, config_path="config/settings.json"):
        """åˆå§‹åŒ–ç›‘æ§å™¨"""
        self.load_config(config_path)
        
        logger.info(f"ç›‘æ§å™¨åˆå§‹åŒ–å®Œæˆ:")
        logger.info(f"  - APIåœ°å€: {self.api_url}")
        logger.info(f"  - æœ€å°æ´»è·ƒé€šé“æ•°: {self.min_active_channels}")
        
    def load_config(self, config_path):
        """åŠ è½½é…ç½®"""
        if Path(config_path).exists():
            with open(config_path, 'r', encoding='utf-8') as f:
                config = json.load(f)
            
            # ä»é…ç½®æ–‡ä»¶è·å–
            self.api_url = config['new_api']['base_url'] + config['new_api']['search_endpoint']
            self.bearer_token = config['new_api']['api_key']
            self.min_active_channels = config['new_api']['min_channels']
            self.upload_script_path = f"python scripts/batch_upload.py"
        else:
            # ä»ç¯å¢ƒå˜é‡è·å–é…ç½®ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™ä½¿ç”¨é»˜è®¤å€¼
            base_url = os.getenv('NEW_API_BASE_URL', 'http://152.53.166.175:3058')
            self.api_url = base_url + '/api/channel/search?keyword=&group=svip&model=&id_sort=true&tag_mode=false'
            self.bearer_token = os.getenv('NEW_API_TOKEN', '')
            self.min_active_channels = int(os.getenv('MIN_CHANNELS', '15'))
            self.upload_script_path = f"python scripts/batch_upload.py"
        
        # æ£€æŸ¥å¿…è¦çš„é…ç½®
        if not self.bearer_token:
            logger.error("è¯·è®¾ç½® NEW_API_TOKEN")
            sys.exit(1)
    
    def get_request_headers(self) -> Dict[str, str]:
        """è·å–è¯·æ±‚å¤´ - æ²¿ç”¨ç”¨æˆ·çš„åŸå§‹è®¾ç½®"""
        return {
            "accept": "application/json, text/plain, */*",
            "accept-language": "zh-CN,zh;q=0.9,en;q=0.8",
            "cache-control": "no-store",
            "new-api-user": "1",
            "authorization": f"Bearer {self.bearer_token}",
            "user-agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36"
        }
    
    def fetch_channel_data(self) -> Dict[str, Any]:
        """
        è·å–é€šé“æ•°æ® - æ²¿ç”¨ç”¨æˆ·çš„åŸå§‹é€»è¾‘
        è¿”å›: APIå“åº”çš„JSONæ•°æ®
        """
        try:
            logger.info("æ­£åœ¨è·å–é€šé“æ•°æ®...")
            
            # å‘é€GETè¯·æ±‚
            response = requests.get(
                self.api_url,
                headers=self.get_request_headers(),
                timeout=30  # 30ç§’è¶…æ—¶
            )
            
            # æ£€æŸ¥HTTPçŠ¶æ€ç 
            if response.status_code != 200:
                logger.error(f"APIè¯·æ±‚å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status_code}")
                logger.error(f"å“åº”å†…å®¹: {response.text}")
                return {}
            
            # è§£æJSONå“åº”
            data = response.json()
            
            # æ£€æŸ¥APIè¿”å›æ˜¯å¦æˆåŠŸ
            if not data.get('success', False):
                logger.error(f"APIè¿”å›å¤±è´¥: {data.get('message', 'æœªçŸ¥é”™è¯¯')}")
                return {}
                
            logger.info("é€šé“æ•°æ®è·å–æˆåŠŸ")
            return data
            
        except requests.RequestException as e:
            logger.error(f"ç½‘ç»œè¯·æ±‚å¼‚å¸¸: {e}")
            return {}
        except json.JSONDecodeError as e:
            logger.error(f"JSONè§£æå¤±è´¥: {e}")
            return {}
        except Exception as e:
            logger.error(f"è·å–é€šé“æ•°æ®æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯: {e}")
            return {}
    
    def analyze_channel_status(self, data: Dict[str, Any]) -> Tuple[int, int, list]:
        """
        åˆ†æé€šé“çŠ¶æ€ - ä¿®æ­£é¢åº¦è®¡ç®—
        å‚æ•°: data - APIè¿”å›çš„æ•°æ®
        è¿”å›: (æ´»è·ƒé€šé“æ•°, éæ´»è·ƒé€šé“æ•°, æ´»è·ƒé€šé“åˆ—è¡¨)
        """
        if not data or 'data' not in data or 'items' not in data['data']:
            logger.warning("APIæ•°æ®æ ¼å¼ä¸æ­£ç¡®æˆ–ä¸ºç©º")
            return 0, 0, []
        
        channels = data['data']['items']
        active_channels = []  # status = 1 çš„é€šé“
        inactive_count = 0    # status != 1 çš„é€šé“æ•°é‡
        
        # éå†æ‰€æœ‰é€šé“ï¼Œç»Ÿè®¡çŠ¶æ€
        for channel in channels:
            channel_id = channel.get('id', 'Unknown')
            channel_name = channel.get('name', 'Unknown')
            status = channel.get('status', 0)
            
            if status == 1:
                active_channels.append({
                    'id': channel_id,
                    'name': channel_name,
                    'used_quota': channel.get('used_quota', 0)
                })
            else:
                inactive_count += 1
                # è®°å½•éæ´»è·ƒé€šé“çš„è¯¦ç»†ä¿¡æ¯
                other_info = channel.get('other_info', '')
                logger.debug(f"éæ´»è·ƒé€šé“ ID:{channel_id} åç§°:{channel_name} çŠ¶æ€:{status} ä¿¡æ¯:{other_info}")
        
        active_count = len(active_channels)
        total_count = len(channels)
        
        logger.info(f"é€šé“çŠ¶æ€ç»Ÿè®¡:")
        logger.info(f"  - æ€»é€šé“æ•°: {total_count}")
        logger.info(f"  - æ´»è·ƒé€šé“æ•° (status=1): {active_count}")
        logger.info(f"  - éæ´»è·ƒé€šé“æ•° (statusâ‰ 1): {inactive_count}")
        
        return active_count, inactive_count, active_channels
    
    def execute_upload_script(self, needed_count: int) -> bool:
        """
        æ‰§è¡Œä¸Šä¼ è„šæœ¬è¡¥å……é€šé“
        å‚æ•°: needed_count - éœ€è¦è¡¥å……çš„é€šé“æ•°é‡
        è¿”å›: æ˜¯å¦æ‰§è¡ŒæˆåŠŸ
        """
        try:
            # æ„é€ å®Œæ•´çš„å‘½ä»¤
            command = f"{self.upload_script_path} {needed_count}"
            logger.info(f"å‡†å¤‡æ‰§è¡Œè¡¥å……è„šæœ¬: {command}")
            
            # æ‰§è¡Œå‘½ä»¤
            result = subprocess.run(
                command,
                shell=True,
                capture_output=True,
                text=True,
                timeout=300  # 5åˆ†é’Ÿè¶…æ—¶
            )
            
            # æ£€æŸ¥æ‰§è¡Œç»“æœ
            if result.returncode == 0:
                logger.info(f"è¡¥å……è„šæœ¬æ‰§è¡ŒæˆåŠŸ!")
                logger.info(f"æ ‡å‡†è¾“å‡º: {result.stdout}")
                return True
            else:
                logger.error(f"è¡¥å……è„šæœ¬æ‰§è¡Œå¤±è´¥ï¼Œè¿”å›ç : {result.returncode}")
                logger.error(f"é”™è¯¯è¾“å‡º: {result.stderr}")
                return False
                
        except subprocess.TimeoutExpired:
            logger.error("è¡¥å……è„šæœ¬æ‰§è¡Œè¶…æ—¶")
            return False
        except Exception as e:
            logger.error(f"æ‰§è¡Œè¡¥å……è„šæœ¬æ—¶å‘ç”Ÿé”™è¯¯: {e}")
            return False
    
    def run_check(self):
        """
        æ‰§è¡Œä¸€æ¬¡ç›‘æ§æ£€æŸ¥ï¼ˆç”¨äºå®šæ—¶ä»»åŠ¡ï¼‰
        """
        try:
            logger.info("=" * 50)
            logger.info("å¼€å§‹æ‰§è¡Œç›‘æ§æ£€æŸ¥")
            
            # 1. è·å–é€šé“æ•°æ®
            data = self.fetch_channel_data()
            if not data:
                logger.warning("è·å–é€šé“æ•°æ®å¤±è´¥ï¼Œæœ¬æ¬¡æ£€æŸ¥ç»“æŸ")
                return
            
            # 2. åˆ†æé€šé“çŠ¶æ€
            active_count, inactive_count, active_channels = self.analyze_channel_status(data)
            
            # 3. æ£€æŸ¥æ˜¯å¦éœ€è¦è¡¥å……é€šé“
            if active_count < self.min_active_channels:
                needed_count = self.min_active_channels - active_count
                logger.warning(f"æ´»è·ƒé€šé“æ•°ä¸è¶³! å½“å‰: {active_count}, æœ€å°éœ€æ±‚: {self.min_active_channels}")
                logger.info(f"éœ€è¦è¡¥å…… {needed_count} ä¸ªé€šé“")
                
                # æ‰§è¡Œè¡¥å……è„šæœ¬
                success = self.execute_upload_script(needed_count)
                if success:
                    logger.info("âœ… é€šé“è¡¥å……å®Œæˆ")
                else:
                    logger.error("âŒ é€šé“è¡¥å……å¤±è´¥")
            else:
                logger.info(f"âœ… é€šé“æ•°é‡å……è¶³ (å½“å‰: {active_count} >= æœ€å°éœ€æ±‚: {self.min_active_channels})")
            
            # 4. æ˜¾ç¤ºæ´»è·ƒé€šé“çš„ç®€è¦ä¿¡æ¯ - ä¿®æ­£é¢åº¦æ˜¾ç¤º
            if active_channels:
                logger.info("å½“å‰æ´»è·ƒé€šé“:")
                for i, channel in enumerate(active_channels[:5], 1):  # åªæ˜¾ç¤ºå‰5ä¸ª
                    quota_dollars = channel['used_quota'] / 500000  # ä¿®æ­£ï¼šé™¤ä»¥500000è½¬æ¢ä¸ºç¾å…ƒ
                    logger.info(f"  {i}. ID:{channel['id']} åç§°:{channel['name']} å·²ç”¨é¢åº¦:${quota_dollars:.2f}")
                if len(active_channels) > 5:
                    logger.info(f"  ... è¿˜æœ‰ {len(active_channels) - 5} ä¸ªæ´»è·ƒé€šé“")
            
            logger.info("æœ¬æ¬¡ç›‘æ§æ£€æŸ¥å®Œæˆ")
            
        except Exception as e:
            logger.error(f"ç›‘æ§è¿‡ç¨‹ä¸­å‘ç”ŸæœªçŸ¥é”™è¯¯: {e}")
            raise

def main():
    """ä¸»å‡½æ•°"""
    print("é€šé“ç›‘æ§è¿ç»´è„šæœ¬ (å®šæ—¶ä»»åŠ¡ç‰ˆæœ¬)")
    print("=" * 35)
    
    # åˆ›å»ºå¹¶è¿è¡Œç›‘æ§å™¨
    try:
        monitor = UptimeMonitor()
        monitor.run_check()
        print("ğŸ‰ ç›‘æ§æ£€æŸ¥æ‰§è¡Œå®Œæˆ!")
    except Exception as e:
        logger.error(f"ç¨‹åºæ‰§è¡Œå¤±è´¥: {e}")
        sys.exit(1)

if __name__ == "__main__":
    main()